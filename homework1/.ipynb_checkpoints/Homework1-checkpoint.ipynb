{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d56fcd57",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38656661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz...\n",
      "Downloading t10k-images-idx3-ubyte.gz...\n",
      "Downloading train-labels-idx1-ubyte.gz...\n",
      "Downloading t10k-labels-idx1-ubyte.gz...\n",
      "Download complete.\n",
      "Save complete.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from urllib import request\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "filename = [\n",
    "[\"training_images\",\"train-images-idx3-ubyte.gz\"],\n",
    "[\"test_images\",\"t10k-images-idx3-ubyte.gz\"],\n",
    "[\"training_labels\",\"train-labels-idx1-ubyte.gz\"],\n",
    "[\"test_labels\",\"t10k-labels-idx1-ubyte.gz\"]\n",
    "]\n",
    "\n",
    "def download_mnist():\n",
    "    base_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "    for name in filename:\n",
    "        print(\"Downloading \"+name[1]+\"...\")\n",
    "        request.urlretrieve(base_url+name[1], \"../datasets/\" + name[1])\n",
    "    print(\"Download complete.\")\n",
    "\n",
    "def save_mnist():\n",
    "    mnist = {}\n",
    "    for name in filename[:2]:\n",
    "        with gzip.open(\"../datasets/\" + name[1], 'rb') as f:\n",
    "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28)\n",
    "    for name in filename[-2:]:\n",
    "        with gzip.open(\"../datasets/\" + name[1], 'rb') as f:\n",
    "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    with open(\"../datasets/\" + \"mnist.pkl\", 'wb') as f:\n",
    "        pickle.dump(mnist,f)\n",
    "    print(\"Save complete.\")\n",
    "\n",
    "def init_mnist():\n",
    "    download_mnist()\n",
    "    save_mnist()\n",
    "    \n",
    "init_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29780579",
   "metadata": {},
   "source": [
    "## 划分训练测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da4a502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取MNIST数据集\n",
    "data_path = r'../datasets/mnist.pkl'\n",
    "def load_data(data_path):\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    return data\n",
    "data = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da55e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = data['training_images'], data['test_images'], data['training_labels'], data['test_labels'], "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dbe4f5f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234c69d",
   "metadata": {},
   "source": [
    "## 对数据进行标准化、归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f7f95b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train /  255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "X_test = (X_test - X_test.mean()) / X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4db195f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b2ad83",
   "metadata": {},
   "source": [
    "## 标签独热编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4aefb514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(labels, num_classes):\n",
    "    one_hot_labels = []\n",
    "    for label in labels:\n",
    "        one_hot = [0] * num_classes\n",
    "        one_hot[label] = 1\n",
    "        one_hot_labels.append(one_hot)\n",
    "    return one_hot_labels\n",
    "\n",
    "num_classes = 10\n",
    "y_train = one_hot_encoding(y_train , num_classes)\n",
    "y_test = one_hot_encoding(y_test , num_classes)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d887af",
   "metadata": {},
   "source": [
    "## 定义网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14f95e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size_1 = 128\n",
    "hidden_size_2 = 64\n",
    "output_size = num_classes\n",
    "'''\n",
    "hidden_size = [X_train.shape[1], 128, 64, num_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a75ffc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 3\n",
    "W, b = [], []\n",
    "W.append(0), b.append(0) # 下标从1开始，更好对应\n",
    "for i in range(num_layers):\n",
    "    w = np.random.randn(hidden_size[i], hidden_size[i + 1]) / np.sqrt(hidden_size[i])\n",
    "    _b = np.zeros(hidden_size[i + 1])\n",
    "    W.append(w)\n",
    "    b.append(_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24731e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Func:\n",
    "    @staticmethod\n",
    "    def relu(x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        exps = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "        return exps / np.sum(exps, axis=-1, keepdims=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def cross_entropy_loss(y_pred, y_true):\n",
    "        n_samples = y_pred.shape[0]\n",
    "        loss = -np.sum(y_true * np.log(y_pred + 1e-12)) / n_samples\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03966162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y_true, learning_rate):\n",
    "    global W, b\n",
    "    # 前向传播\n",
    "    Z, A = [], []\n",
    "    Z.append(0), A.append(X) # 下标从1开始。A[0]其实就是输入X\n",
    "    for i in range(num_layers):\n",
    "        z = np.dot()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b35373",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y_true, learning_rate):\n",
    "    global W1, W2, W3, b1, b2, b3\n",
    "    # 前向传播\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = relu(z2)\n",
    "    z3 = np.dot(a2, W3) + b3\n",
    "    y_pred = softmax(z3)\n",
    "    m = y_true.shape[0]\n",
    "    # 计算损失函数值和梯度\n",
    "    loss = cross_entropy_loss(y_pred, y_true)\n",
    "\n",
    "    grad_y_pred = y_pred - y_true\n",
    "\n",
    "    grad_W3 = 1./m*np.dot(a2.T, grad_y_pred)\n",
    "    grad_b3 = 1./m*np.sum(grad_y_pred, axis=0)\n",
    "    grad_a2 = np.dot(grad_y_pred, W3.T)\n",
    "\n",
    "    grad_z2 = grad_a2.copy()\n",
    "    grad_z2[z2 < 0] = 0\n",
    "    grad_W2 = 1./m*np.dot(a1.T, grad_z2)\n",
    "    grad_b2 = 1./m*np.sum(grad_z2, axis=0)\n",
    "    grad_a1 = np.dot(grad_z2, W2.T)\n",
    "\n",
    "    grad_z1 = grad_a1.copy()\n",
    "    grad_z1[z1 < 0] = 0\n",
    "    grad_W1 = 1./m*np.dot(X.T, grad_z1)\n",
    "    grad_b1 = 1./m*np.sum(grad_z1, axis=0)\n",
    "\n",
    "    # 更新权重和偏置\n",
    "    W3 -= learning_rate * grad_W3\n",
    "    b3 -= learning_rate * grad_b3\n",
    "    W2 -= learning_rate * grad_W2\n",
    "    b2 -= learning_rate * grad_b2\n",
    "    W1 -= learning_rate * grad_W1\n",
    "    b1 -= learning_rate * grad_b1\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf92789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c61e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395a9e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65334f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4602ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8a6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
